{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 Algorithm\n",
    "\n",
    "Method by which a decision tree can be generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the entropy of a set $S$ with ${n}_{pos}$ positive observations and ${n}_{neg}$ negative\n",
    "observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of a set $S$ is given by equation:\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    " entropy(S) = - \\sum_{c=1}^C p_c log_2 p_c,\n",
    "\\end{equation*}\n",
    "\n",
    "where $C$ is the number of classes (2 in our case since we have a positive and a negative class) and $p_c$ is the frequency of class $c$ in the set $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017, 2018 and 2019 Question Example\n",
    "df = pd.DataFrame({\"G\":[0,1,1,0,0,0,1,1,0,1], \"A\":[1,1,3,2,2,1,2,3,3,1], \"B\":[1,1,1,0,1,0,1,1,0,1], \"T\":[1,1,0,0,1,0,1,1,0,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "def entropy(S):\n",
    "    entropy = 0\n",
    "    n = len(S)\n",
    "    frequencies = Counter(S)\n",
    "    \n",
    "    for key in frequencies.keys():\n",
    "        pc = frequencies[key]/n\n",
    "        entropy += (pc)*math.log(pc, 2)\n",
    "    \n",
    "    return -1*entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: G\n",
      "Entropy: 1.0\n",
      "\n",
      "Attribute: A\n",
      "Entropy: 1.5709505944546684\n",
      "\n",
      "Attribute: B\n",
      "Entropy: 0.8812908992306927\n",
      "\n",
      "Attribute: T\n",
      "Entropy: 0.9709505944546686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for attr in df.columns:\n",
    "    print(\"Attribute: {}\\nEntropy: {}\\n\".format(attr, entropy(df[attr])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes as input a set $S$ of examples and an feature $A$ from these examples,\n",
    "and calculates the Information Gain, denoted as $gain(S,A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Information Gain is defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    " gain(S,A) = entropy(S) - \\sum_{i} \\frac{|S_{u_i}|}{|S|} entropy(S_{u_i}),\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $S_{u_i}$ is the subset of examples from $S$ whose feature $A$ is equal to the $i^{th}$ possible value that $A$ can take. For example, the feature _Temperature_ can take on of three possible values: _Hot,_ _Mild,_ or _Cool;_ hence $S_{u_i}$ = $S_{Hot}$ denotes all the examples that have the _Hot_ value for the _Temperature_ feature. The\n",
    "$\\sum_{i}$ summation over $i$ indicates we are summing over all the possible values $u_i$ of feature $A$. Finally, $|S|$ and $|S_{u_i}|$ denote the cardinality of the set $S$ and subset $S_{u_i}$ respectively (cardinality = number of elements of the set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(df, feature, target):\n",
    "#     Work out entropy of target column\n",
    "#     Work out the entropy of the target column with respect to the different values in the feature column\n",
    "    f_vals = df[feature].unique() # Ui\n",
    "    gain = entropy(df[target]) # ent(S)\n",
    "    t_size = len(df[target]) # |S|\n",
    "    for key in f_vals:\n",
    "        sui = df[df[feature] == key][target] # Sui\n",
    "        gain -= (len(sui)/t_size)*entropy(sui)\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the Information Gain of all the attributes. Which one would you choose for the root node (or first decision stump) of your decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: G\n",
      "Info Gain: 0.12451124978365313\n",
      "\n",
      "Attribute: A\n",
      "Info Gain: 0.09546184423832182\n",
      "\n",
      "Attribute: B\n",
      "Info Gain: 0.5567796494470394\n",
      "\n",
      "Attribute: T\n",
      "Info Gain: 0.9709505944546686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for attr in df.columns:\n",
    "    print(\"Attribute: {}\\nInfo Gain: {}\\n\".format(attr, info_gain(df, attr, \"T\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree induction\n",
    "\n",
    "Algorithm 1 below shows the pseudo-code of the ID3 Decision Tree algorithm, which is a recursive algorithm that computes a decision tree based on a metric; in the case, the metric is Information Gain. Implement the ID3 algorithm and test it with the _play_tennis_ dataset; in other words, compute the training error. Note that the column _Day_ is not an attribute, it is only used to organize the examples. Also note that in Algorithm 1, Observations = Examples, Targets = Labels, and Attributes = Features.\n",
    "\n",
    "## Algorithm 1:  ID3 Decision Tree Algorithm\n",
    "\n",
    "**ID3** (Observations, Targets, Attributes)<br>\n",
    "\n",
    "**if** all Observations are class +1 **then**<br>\n",
    "&emsp; **return** single-node tree Root with label +1<br>\n",
    "**if** all Observations are class -1 **then**<br>\n",
    "&emsp; **return** single-node tree Root with label -1<br>\n",
    "**if** Attributes is empty **then**<br>\n",
    "&emsp; **return** single-node tree Root with label of most common value in Targets<br>\n",
    "**else**<br>\n",
    "&emsp;**begin**<br>\n",
    "&emsp;$A$ $\\leftarrow$ best attribute from Attributes (highest Information Gain)<br>\n",
    "&emsp;The decision attribute for Root $\\leftarrow$  $A$<br>\n",
    "&emsp;**for** each possible vale $u_i$ of $A$: **do**<br>\n",
    "&emsp;&emsp;Add a new tree branch below Root for $A = u_i$<br>\n",
    "&emsp;&emsp;$S_{u_i}$ $\\leftarrow$  Subset of Observations with $A = u_i$<br>\n",
    "&emsp;&emsp;**if** $S_{u_i}$ is empty **then**<br>\n",
    "&emsp;&emsp;&emsp;Add leaf node with label the most common value in Targets<br>\n",
    "&emsp;&emsp;**else**<br>\n",
    "&emsp;&emsp;&emsp;Add below branch **ID3**($S_{u_i},$  Targets, Attributes - {$A$})<br>\n",
    "&emsp; **end**<br>\n",
    "**return** Root<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, label):\n",
    "        self.children = []\n",
    "        self.label = label\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(S, target):\n",
    "    if set(S[target].values) == set([1]):\n",
    "        return Node(1)\n",
    "    if set(S[target].values) == set([0]):\n",
    "        return Node(0)\n",
    "    if list(S.columns.drop([target])) == []:\n",
    "        return Node(S[target].mode()[0])\n",
    "    else:\n",
    "        attr_per_info_gain = {info_gain(S, attr, target):attr for attr in sorted(S.columns.drop(target), reverse=True)}\n",
    "        best_attr = attr_per_info_gain[max(attr_per_info_gain.keys())]\n",
    "        root = Node(best_attr)\n",
    "        for u in S[best_attr].unique():\n",
    "            child = Node(u)\n",
    "            root.add_child(child)\n",
    "            new_S = S[S[best_attr] == u]\n",
    "            if list(new_S[target]) == []:\n",
    "                child.add_child(Node(S[target].mode()[0]))\n",
    "            else:\n",
    "                child.add_child(ID3(new_S.drop([best_attr], axis = 1),target))\n",
    "    return root\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ID3(df,\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "   | 1\n",
      "   |   | A\n",
      "   |   |   | 1\n",
      "   |   |   |   | 1\n",
      "   |   |   | 3\n",
      "   |   |   |   | G\n",
      "   |   |   |   |   | 1\n",
      "   |   |   |   |   |   | 0\n",
      "   |   |   | 2\n",
      "   |   |   |   | 1\n",
      "   | 0\n",
      "   |   | 0\n"
     ]
    }
   ],
   "source": [
    "print(tree.label)\n",
    "def print_tree(tree, tabs):\n",
    "    for child in tree.children:\n",
    "        print(\"{} {}\".format(tabs*\"   |\", child.label))\n",
    "        print_tree(child, tabs+1)\n",
    "print_tree(tree, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
