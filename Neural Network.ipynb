{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1118,  0.4961,  0.6265,  ...,  0.2535,  1.8279,  1.8019],\n",
      "        [-0.2479,  0.9366, -0.4085,  ..., -0.5885,  0.0706,  0.1947],\n",
      "        [ 0.8365,  0.2150,  0.6226,  ..., -2.2067,  0.6357,  0.8513],\n",
      "        ...,\n",
      "        [ 0.1751, -0.1399, -1.6180,  ...,  0.2891,  0.5940, -1.0395],\n",
      "        [ 0.3063, -0.6144,  0.2854,  ...,  0.3062,  0.2940, -0.2030],\n",
      "        [ 0.6562, -0.5939,  0.7462,  ...,  0.1301,  1.5760, -0.3123]])\n",
      "tensor([[ 0.8673, -0.5654, -0.0657, -0.0244, -1.5281,  0.9474, -0.1647, -0.6903,\n",
      "          0.8883,  0.4386],\n",
      "        [ 0.8111,  0.6668, -1.6443, -0.9340, -0.3280, -1.6888, -0.8428, -1.6820,\n",
      "          1.7384,  0.2603],\n",
      "        [-1.1613,  1.0089,  1.0815,  0.1803, -0.0124,  0.1631,  1.1317,  1.0368,\n",
      "         -0.4118, -1.6624],\n",
      "        [ 0.3495, -0.2790, -0.3093,  0.0655, -0.0977, -0.1126, -0.9806, -0.4427,\n",
      "         -2.8448, -0.9023],\n",
      "        [ 0.8096,  0.7898,  2.1678,  0.0281,  1.2755,  0.2944, -0.6656,  0.7515,\n",
      "         -0.6067, -0.8186],\n",
      "        [-0.0419, -0.6566, -1.2227, -1.5145, -0.2918,  0.7417,  0.5603, -0.6639,\n",
      "          0.1398, -0.3585],\n",
      "        [-0.3296, -1.0075, -1.0954,  1.2858, -1.1731, -0.3134, -0.2240, -0.4037,\n",
      "         -0.6800, -1.3728],\n",
      "        [ 0.7901, -1.9013,  1.0650, -0.8654, -0.2753, -0.9944,  0.4074,  1.7136,\n",
      "          0.4444, -0.1362],\n",
      "        [-0.0886, -0.8111,  1.5322, -0.1746, -0.1365,  1.6340, -1.4652, -0.4095,\n",
      "         -0.3037,  0.7678],\n",
      "        [ 0.8134,  0.3431,  1.2447, -0.4309, -1.2603,  0.0153,  0.8273,  2.3939,\n",
      "         -0.9430, -1.0603],\n",
      "        [-1.5428, -0.4457, -0.5294,  1.4569, -1.2951, -0.3989, -0.3143,  0.3555,\n",
      "         -0.0170,  0.8017],\n",
      "        [-0.3753,  0.6594,  0.8836,  0.1758, -0.2220,  0.6942, -0.7733, -0.8448,\n",
      "         -0.4417,  0.7310],\n",
      "        [ 0.9660,  0.7853,  0.1548,  2.0368,  0.3650,  0.8271,  0.9824,  1.3343,\n",
      "          0.5270, -0.1701],\n",
      "        [ 0.1986,  1.4619,  2.2324,  1.2926, -0.9519, -0.6748,  0.2138, -0.4390,\n",
      "         -2.0335, -0.7200],\n",
      "        [ 0.6698,  0.3061,  1.4468, -0.5632, -0.5801,  0.2905,  0.0807,  1.1189,\n",
      "          1.6180, -0.9910],\n",
      "        [-0.0052, -0.0543,  1.1968, -0.3306, -0.5784, -1.1478, -1.0511,  0.3403,\n",
      "          0.6645,  0.3015],\n",
      "        [ 0.2452,  0.8294, -0.3696,  0.9426,  0.1496, -0.7697, -0.1670,  0.2356,\n",
      "         -0.1293,  0.7594],\n",
      "        [ 0.3204,  1.2808,  2.1114, -0.8102, -1.4381, -1.5194,  1.0064, -0.1740,\n",
      "         -2.9147,  0.2290],\n",
      "        [-1.3875,  0.5857, -2.1876,  0.1764, -0.0868, -0.6757, -1.1304, -0.3844,\n",
      "          1.4074, -1.3793],\n",
      "        [ 0.7829, -0.6678,  0.3038,  1.0383, -0.1349,  1.0845, -2.4377, -0.3498,\n",
      "          0.2315,  1.0698],\n",
      "        [ 2.0203, -0.5786, -0.8777, -1.4059,  0.3582, -0.0404, -0.3893,  1.2750,\n",
      "         -1.7201,  1.5812],\n",
      "        [ 0.8053,  0.3832, -0.8294, -0.7833,  0.4391,  1.1896,  0.6183,  0.6610,\n",
      "         -0.7800, -0.0432],\n",
      "        [-0.0145,  2.0832,  0.3241, -0.3659, -1.0850, -0.0447, -0.4625, -0.5090,\n",
      "          0.6786, -0.7016],\n",
      "        [ 0.5829, -1.4148,  0.0511,  0.8872, -1.1404, -0.4079, -0.2441,  0.6352,\n",
      "         -0.0734,  0.1314],\n",
      "        [-1.0658,  1.2171, -0.7141,  0.0801,  2.9171, -2.7728,  0.3754,  0.3477,\n",
      "         -2.0208,  0.2604],\n",
      "        [-0.0622,  0.8499, -0.8895,  0.4061, -0.1075, -1.8659,  0.7239,  1.5365,\n",
      "         -1.0777, -1.3150],\n",
      "        [ 0.1755, -0.4633, -0.4228, -1.8035, -1.7118, -0.0114, -1.7768,  0.8867,\n",
      "          0.0856, -0.9781],\n",
      "        [-0.9315,  0.4280,  0.4952,  0.6177,  0.3538,  0.8045, -0.9532, -0.2971,\n",
      "          0.5741, -1.4494],\n",
      "        [-0.3397,  1.5562, -0.2856,  0.2291, -0.7952, -0.1476, -0.1958,  1.5257,\n",
      "         -0.3947, -0.3891],\n",
      "        [-0.5207, -1.7327,  0.2084, -0.4966, -0.6023,  1.5939, -0.4800,  1.4796,\n",
      "         -0.1767,  0.3527],\n",
      "        [-0.8498, -0.2663, -1.0507, -0.0960, -2.0344,  1.6068,  1.0687, -0.8210,\n",
      "         -0.2446, -0.4837],\n",
      "        [-1.6211,  1.3946, -0.3071, -1.9569,  0.9498,  1.7010, -0.5226, -0.6441,\n",
      "          1.4420,  0.7076],\n",
      "        [ 0.5058,  0.2804,  0.5862,  1.5199,  0.9130,  0.8554,  1.2249, -1.2928,\n",
      "         -1.6001, -1.5503],\n",
      "        [ 2.1147,  1.4319,  1.1597,  0.9100,  0.5246, -1.0572,  0.3716, -0.4025,\n",
      "          0.2333, -0.3091],\n",
      "        [ 1.6186,  0.1678,  1.4366, -0.0485, -0.3425, -0.8159,  0.8562, -0.1609,\n",
      "          1.5387, -0.1854],\n",
      "        [-0.9065,  0.0379, -2.0863,  0.1016,  1.3327,  0.9677, -1.8545, -0.3398,\n",
      "         -0.2887,  0.9683],\n",
      "        [-0.9564, -0.8458, -0.3768, -1.8801,  1.2001, -0.4887, -0.3414,  0.5242,\n",
      "          1.3706,  1.3496],\n",
      "        [ 1.3501,  0.5691,  0.4523,  0.6896,  1.3949,  1.2464, -0.2884,  2.3859,\n",
      "          0.9137,  1.3487],\n",
      "        [ 1.7250,  0.1596,  1.5032,  0.0463, -1.7180, -0.1872,  1.2303,  1.1262,\n",
      "          0.0067, -0.6764],\n",
      "        [-0.1473, -1.2009,  0.0070, -0.0481, -1.0332,  0.7697, -0.7298, -0.2051,\n",
      "         -0.4280,  0.4847],\n",
      "        [-0.9280, -0.2815,  0.7852, -0.3087, -1.4854,  0.2457, -0.3018,  1.1500,\n",
      "          0.3366,  2.9492],\n",
      "        [-0.2930,  1.6229,  1.2380,  0.3327, -0.7784, -1.8953,  1.0573, -0.9186,\n",
      "          0.7667, -0.0331],\n",
      "        [-0.0569,  0.8189, -0.5187, -2.6543, -1.4831, -0.5534, -2.0146,  1.0966,\n",
      "         -0.8407,  0.1728],\n",
      "        [ 0.6527,  0.1938, -0.6102,  0.2837, -0.3823, -0.7008, -0.4094,  0.2549,\n",
      "          0.0099,  0.2839],\n",
      "        [-0.8347,  0.9678,  0.6546,  0.4288,  0.3315,  0.3744,  2.8899,  1.8701,\n",
      "          0.9739,  0.4566],\n",
      "        [-0.7517,  0.8848, -0.4953, -0.2685, -0.1149,  0.3492,  0.4748, -2.2076,\n",
      "          0.1900, -0.3484],\n",
      "        [-1.1289, -0.5668, -0.7914, -1.0506, -0.4154,  1.3286, -1.4670,  0.2780,\n",
      "          0.4813,  0.6381],\n",
      "        [ 0.4555,  0.8305, -2.1854,  0.1071,  0.9102, -0.9410, -0.4426, -0.5013,\n",
      "         -0.7465, -0.3202],\n",
      "        [ 1.0832, -0.0477,  1.2940,  0.2298,  2.0675, -1.1021,  0.7672, -0.0059,\n",
      "         -0.2302,  0.1962],\n",
      "        [ 0.8939,  0.0659,  0.3958, -0.1983, -1.1491, -0.9203, -0.8723, -0.1459,\n",
      "          1.9763, -0.2305],\n",
      "        [ 0.0613, -0.0612,  0.6259,  2.8570, -1.5392, -0.3377, -3.0603, -0.6415,\n",
      "          1.6089,  0.6889],\n",
      "        [-0.0771, -0.5642, -1.0136, -0.5645,  2.3644, -0.2688, -0.2451,  0.0920,\n",
      "          0.4955, -1.2187],\n",
      "        [-0.3646,  0.7435,  1.3704, -0.3931, -0.2797,  0.6932, -0.7064,  0.5588,\n",
      "         -0.8146, -0.1307],\n",
      "        [ 1.1211,  1.2394,  1.3712,  0.5365, -1.1974,  0.5960, -0.0241,  1.4785,\n",
      "          0.4134, -1.2650],\n",
      "        [-0.6968,  1.5741, -0.2185, -0.7657, -0.3952, -0.7184, -0.6034, -1.0042,\n",
      "         -0.1976, -0.3321],\n",
      "        [ 0.9327, -1.0148, -1.2933,  0.1019,  0.8131, -0.5856, -0.2104, -1.8119,\n",
      "         -0.1753, -1.8267],\n",
      "        [ 0.2927, -0.6466,  0.5925, -1.6512, -0.3529, -1.0026,  0.3946, -0.2543,\n",
      "         -1.0962,  0.6500],\n",
      "        [-0.9350,  0.1086,  0.8520,  0.1939, -2.3854,  0.6251, -0.1112,  0.8687,\n",
      "         -0.9623,  1.6392],\n",
      "        [ 0.3501, -0.6392,  0.8244,  0.3439,  1.2550,  0.2197,  0.0443, -0.0649,\n",
      "         -0.2444,  1.0423],\n",
      "        [ 0.9813,  1.0952, -0.7457,  2.6788, -0.6031, -0.4247, -0.5693,  0.6950,\n",
      "          0.3831, -1.2584],\n",
      "        [ 0.7963, -1.2849,  1.3938,  0.8455,  0.2257,  0.0719,  0.4472,  1.2601,\n",
      "          0.4911, -0.5692],\n",
      "        [-0.6021,  0.8664,  0.2813,  1.1766,  2.2320, -1.7175, -0.2227,  0.0390,\n",
      "          0.7067, -0.4451],\n",
      "        [-1.0504, -0.3958, -0.2961, -0.6677,  0.6052,  0.9170, -0.0035,  0.6544,\n",
      "          0.1125, -0.4895],\n",
      "        [ 1.4214, -0.6872, -0.4642,  1.2905,  0.5041,  0.6483, -2.0429, -1.1784,\n",
      "         -1.7524, -1.3236]])\n",
      "99 1124.822265625\n",
      "199 11.14970588684082\n",
      "299 0.20815110206604004\n",
      "399 0.0054648257791996\n",
      "499 0.00037375095416791737\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "print(x)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "print(y)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half = w1.t().mm(x.t()).shape\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc3805f41a1a645b8af5e0e9de896cc42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
