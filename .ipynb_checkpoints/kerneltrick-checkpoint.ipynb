{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/FreddieBrown/51d7431c029980b821ca91b139986c86/kerneltrick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vk5XQPUZ_6SN"
   },
   "source": [
    "**Kernel Trick**\n",
    "\n",
    "Kernel trick is a method by which linear data is taken to projected into a polynomial space. For example, if you had a class of data surrounded by another class, you could transform the central class to a polynomial space to seperate the classes.\n",
    "\n",
    "The main point of kernel trick is that it uses the differences between values. When it is training, it looks at the differences in examples within the training data. It is a bit like a roided up version of KNN. \n",
    "\n",
    "When using the test data, it is working out the difference between the test data, and the data which it has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKUn_YajQlfc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2000\n",
    "small_rad = 10\n",
    "big_rad = 40\n",
    "def generate_data():\n",
    "    data_points = np.random.rand(n,2)*10\n",
    "    y = np.zeros((n))\n",
    "    #print(y)\n",
    "    for i, d in enumerate(data_points):\n",
    "        a = d[0]**2+d[1]**2\n",
    "        if a>small_rad:\n",
    "            if a<big_rad:\n",
    "                y[i]=1\n",
    "            else:\n",
    "                y[i]=-1\n",
    "        else:\n",
    "            y[i]=-1\n",
    "    data_points += np.random.rand(n,2)*2-1 #add some noise\n",
    "    plt.scatter([d[0] for d in data_points], [d[1] for d in data_points], color = ['r' if i==1 else 'b' for i in y])\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    return data_points, y\n",
    "\n",
    "X_train, Y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will show how to generate a prediction for a dataset \n",
    "using Kernel trick with a Gaussian Kernel.\n",
    "\"\"\"\n",
    "# Training and Test Data\n",
    "# X_train = np.array([[2, 4],\n",
    "#     [2, 3]])\n",
    "train_mean = np.mean(X_train)\n",
    "train_std = np.std(X_train)\n",
    "vectorized_centring = np.vectorize(lambda i: (i-train_mean)/train_std)\n",
    "# cented_X_train = vectorized_centring(X_train)\n",
    "# X_test = np.array([[2, 4],\n",
    "#     [2, 3]])\n",
    "# cented_X_test = vectorized_centring(X_test)\n",
    "# Y_train =[[1],[-1]]\n",
    "# Y_test = [[1],[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "_bPLHrfyDvJ1",
    "outputId": "ba3bf7dd-deb6-4e30-b1fd-f01d6ea09099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K: [[1.         2.07508061]\n",
      " [2.07508061 1.        ]]\n",
      "\n",
      "U: [[-0.93016281]\n",
      " [ 0.93016281]]\n",
      "\n",
      "~K: [[1.         2.07508061]\n",
      " [2.07508061 1.        ]]\n",
      "\n",
      "Predictions: [[ 1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "# This is the method which uses a gaussian kernel\n",
    "def gaussian(xi, xj):\n",
    "    \"\"\"This function will implement gaussian kernel\"\"\"\n",
    "    pwr = round(0.5*(np.linalg.norm(np.subtract(xi,xj), ord=2)**2), 2)\n",
    "    return np.exp(pwr, dtype=np.float64)\n",
    "\n",
    "def kernel_trick(X1, X2, k):\n",
    "    \"\"\"\n",
    "    This function will use a defined kernel and will set every index \n",
    "    of a K matrix. This matrix can be used to calculate weightings for \n",
    "    a prediction. The Matrix will be a NxN matrix of values where N is \n",
    "    the size of X. When calculating K, X1 = X2. When calculating test \n",
    "    data, X1 is the test data and X2 is the training data.\n",
    "    \"\"\"\n",
    "    K = []\n",
    "    for i in range(0, len(X1)):\n",
    "        K.append([])\n",
    "        for j in range(0, len(X2)):\n",
    "            K[i].append(k(X1[i], X2[j]))\n",
    "    return K\n",
    "# Create the K matrix for training data (K)\n",
    "K_train = np.asarray(kernel_trick(cented_X_train, cented_X_train, gaussian))\n",
    "print(\"\\nK: {}\".format(K_train))\n",
    "\n",
    "# Generate the weightings for the prediction\n",
    "U = np.matmul(np.linalg.inv(K_train), Y_train)\n",
    "print(\"\\nU: {}\".format(U))\n",
    "\n",
    "# Generate the value of ~K, used for predicting labels of test data\n",
    "K_test = np.asarray(kernel_trick(cented_X_test, cented_X_train, gaussian))\n",
    "print(\"\\n~K: {}\".format(K_test))\n",
    "\n",
    "# Using the test data and weightings to predict the test labels\n",
    "predictions = np.sign(np.matmul(K_test, U))\n",
    "print(\"\\nPredictions: {}\".format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "dXtpa-BHQlfq",
    "outputId": "71da5085-8fe0-4b18-9753-cd9185ac61f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Z: [[ 1.         -0.90453403  1.50755672  0.81818182 -1.36363636  2.27272727]\n",
      " [ 1.         -0.90453403  0.30151134  0.81818182 -0.27272727  0.09090909]]\n",
      "\n",
      "~Z: [[ 1.         -0.90453403  1.50755672  0.81818182 -1.36363636  2.27272727]\n",
      " [ 1.         -0.90453403  0.30151134  0.81818182 -0.27272727  0.09090909]]\n",
      "\n",
      "K: [[11.78512397  3.52066116]\n",
      " [ 3.52066116  2.66115702]]\n",
      "\n",
      "~K: [[11.78512397  3.52066116]\n",
      " [ 3.52066116  2.66115702]]\n",
      "\n",
      "U: [[ 0.32592475]\n",
      " [-0.80696877]]\n",
      "\n",
      "Predictions: [[ 1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "# Another way to do it, is purely through matrix multiplication\n",
    "\"\"\"\n",
    "Change of basis from linear space to polynomial space for both training\n",
    "and test data\n",
    "\n",
    "X = [[A, B], [C, D]]\n",
    "\n",
    "Z = [[1, A, B, A^2, AB, B^2], [1, C, D, C^2, CD, D^2]]\n",
    "\"\"\"\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "Z_train = poly.fit_transform(cented_X_train)\n",
    "print(\"\\nZ: {}\".format(Z_train))\n",
    "Z_test = poly.fit_transform(cented_X_test)\n",
    "print(\"\\n~Z: {}\".format(Z_test))\n",
    "\n",
    "# Use these Z matricies to build a K matrix and a ~K matrix\n",
    "\n",
    "K_train = np.matmul(Z_train, np.transpose(Z_train))\n",
    "print(\"\\nK: {}\".format(K_train))\n",
    "K_test = np.matmul(Z_test, np.transpose(Z_train))\n",
    "print(\"\\n~K: {}\".format(K_test))\n",
    "\n",
    "# Calculate regression weights\n",
    "\n",
    "U = np.matmul(np.linalg.inv(K_train), Y_train)\n",
    "print(\"\\nU: {}\".format(U))\n",
    "\n",
    "# Calculate predictions\n",
    "predictions = np.sign(np.matmul(K_test, U))\n",
    "print(\"\\nPredictions: {}\".format(predictions))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "KernelTrick.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
